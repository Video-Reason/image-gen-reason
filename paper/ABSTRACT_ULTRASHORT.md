# Abstract (Ultra-Short Version - 120 words)

## Video Models Start to Solve Chess, Maze, Sudoku, Mental Rotation, and Raven's Matrices

We introduce VMEvalKit, the first systematic framework for evaluating reasoning in video generation models. Testing 40 models across 11 families on five cognitive tasks—chess, maze navigation, Sudoku, 3D mental rotation, and Raven's matrices—we show that leading models (Sora, Veo 3.1) achieve >60% success rates, demonstrating measurable visual problem-solving capabilities. Our "Task Pair" paradigm (initial state → solution state) enables objective evaluation. Statistical validation across 450 samples shows automated GPT-4O evaluation strongly correlates with human judgment (r=0.949, κ=0.867, p=0.051). We release an open-source framework supporting extensible model and task integration, establishing infrastructure for large-scale benchmarking and reinforcement learning-based improvements. Video generation is transitioning from photorealism to problem-solving.

